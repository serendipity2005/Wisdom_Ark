import OpenAI from 'openai';
import toolsMap from './aiTools';
import { zodToJsonSchema } from 'zod-to-json-schema';

// ================== AI æœåŠ¡é…ç½® =================
interface AIServiceConfig {
  id: string;
  name: string;
  priority: number;
  client: OpenAI;
  model: string;
  status: 'online' | 'offline' | 'checking';
  responseTime: number | null;
  consecutiveFailures: number;
  lastCheck: Date | null;
  lastSuccess: Date | null;
}

const AI_SERVICES: AIServiceConfig[] = [
  {
    id: 'primary',
    name: 'ChatAnywhere (ä¸»æœåŠ¡)',
    priority: 1,
    client: new OpenAI({
      apiKey: 'sk-MhhXBfjcOEJb5eOOjBb0bn8P0qcLaQFE0sVOZTCb5OradbEd',
      baseURL: 'https://api.chatanywhere.tech/v1',
      dangerouslyAllowBrowser: true,
    }),
    model: 'gpt-5-mini',
    status: 'checking',
    responseTime: null,
    consecutiveFailures: 0,
    lastCheck: null,
    lastSuccess: null,
  },
  {
    id: 'backup1',
    name: 'OpenAI Direct (å¤‡ç”¨)',
    priority: 2,
    client: new OpenAI({
      //   apiKey: '0f513bc89a482ed8fe9d4b6369eac7d8',
      //   baseURL: 'https://spark-api-open.xf-yun.com/v2/chat/completions',
      apiKey: 'sk-MhhXBfjcOEJb5eOOjBb0bn8P0qcLaQFE0sVOZTCb5OradbEd',
      baseURL: 'https://api.chatanywhere.tech/v1',
      dangerouslyAllowBrowser: true,
    }),
    model: 'gpt-4o-mini',
    status: 'checking',
    responseTime: null,
    consecutiveFailures: 0,
    lastCheck: null,
    lastSuccess: null,
  },
  // {
  //   id: 'backup2',
  //   name: 'deepseek',
  //   priority: 3,
  //   client: new OpenAI({
  //     apiKey: 'sk-529ce6e9488446a59323d1950ea1dc8a',
  //     baseURL: 'https://api.deepseek.com',
  //     dangerouslyAllowBrowser: true,
  //   }),
  //   model: 'gpt-4o-mini',
  //   status: 'checking',
  //   responseTime: null,
  //   consecutiveFailures: 0,
  //   lastCheck: null,
  //   lastSuccess: null,
  // },
];

// ==================== æœåŠ¡ç®¡ç†å™¨ ====================
class AIServiceManager {
  private services: AIServiceConfig[];
  private currentService: AIServiceConfig | null = null;
  private healthCheckInterval: NodeJS.Timeout | null = null;
  private onServiceChangeCallback?: (service: AIServiceConfig) => void;

  constructor(services: AIServiceConfig[]) {
    this.services = services.sort((a, b) => a.priority - b.priority);
    this.selectBestService();
  }

  // å¯åŠ¨å¥åº·æ£€æŸ¥
  startHealthCheck(interval = 30000) {
    this.performHealthCheck();
    this.healthCheckInterval = setInterval(() => {
      this.performHealthCheck();
    }, interval);
  }

  // åœæ­¢å¥åº·æ£€æŸ¥
  stopHealthCheck() {
    if (this.healthCheckInterval) {
      clearInterval(this.healthCheckInterval);
      this.healthCheckInterval = null;
    }
  }

  // æ‰§è¡Œå¥åº·æ£€æŸ¥
  async performHealthCheck() {
    const checkPromises = this.services.map(async (service) => {
      try {
        const startTime = Date.now();

        // ç®€å•çš„æ¨¡å‹åˆ—è¡¨æ£€æŸ¥ä½œä¸ºå¥åº·æ£€æŸ¥
        await service.client.models.list();

        const responseTime = Date.now() - startTime;
        service.status = 'online';
        service.responseTime = responseTime;
        service.lastCheck = new Date();
        service.consecutiveFailures = 0;

        console.log(`âœ… ${service.name} å¥åº·æ£€æŸ¥é€šè¿‡ (${responseTime}ms)`);
      } catch (error) {
        service.status = 'offline';
        service.consecutiveFailures += 1;
        service.lastCheck = new Date();
        console.error(`âŒ ${service.name} å¥åº·æ£€æŸ¥å¤±è´¥:`, error);
      }
    });

    await Promise.allSettled(checkPromises);
    this.selectBestService();
  }

  // é€‰æ‹©æœ€ä½³æœåŠ¡
  selectBestService() {
    const availableServices = this.services.filter(
      (s) => s.status === 'online',
    );

    if (availableServices.length === 0) {
      console.warn('âš ï¸ æ²¡æœ‰å¯ç”¨çš„ AI æœåŠ¡');
      this.currentService = null;
      return null;
    }

    // é€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜ä¸”å“åº”æœ€å¿«çš„æœåŠ¡
    const bestService = availableServices.reduce((best, current) => {
      if (current.priority < best.priority) return current;
      if (
        current.priority === best.priority &&
        (current.responseTime || 0) < (best.responseTime || 0)
      ) {
        return current;
      }
      return best;
    });

    if (!this.currentService || this.currentService.id !== bestService.id) {
      console.log(`ğŸ”„ åˆ‡æ¢åˆ°æœåŠ¡: ${bestService.name}`);
      this.currentService = bestService;
      this.onServiceChangeCallback?.(bestService);
    }

    return bestService;
  }

  // è·å–å½“å‰æœåŠ¡
  getCurrentService(): AIServiceConfig | null {
    return this.currentService;
  }

  // æ ‡è®°æœåŠ¡å¤±è´¥
  markServiceFailure(serviceId: string) {
    const service = this.services.find((s) => s.id === serviceId);
    if (service) {
      service.consecutiveFailures += 1;

      // è¿ç»­å¤±è´¥3æ¬¡æ ‡è®°ä¸ºç¦»çº¿
      if (service.consecutiveFailures >= 3) {
        service.status = 'offline';
        console.warn(
          `âš ï¸ ${service.name} è¢«æ ‡è®°ä¸ºç¦»çº¿ (è¿ç»­å¤±è´¥${service.consecutiveFailures}æ¬¡)`,
        );
        this.selectBestService();
      }
    }
  }

  // æ ‡è®°æœåŠ¡æˆåŠŸ
  markServiceSuccess(serviceId: string) {
    const service = this.services.find((s) => s.id === serviceId);
    if (service) {
      service.consecutiveFailures = 0;
      service.lastSuccess = new Date();
      if (service.status === 'offline') {
        service.status = 'online';
        this.selectBestService();
      }
    }
  }

  // è·å–æ‰€æœ‰æœåŠ¡çŠ¶æ€
  getServicesStatus() {
    return this.services.map((s) => ({
      id: s.id,
      name: s.name,
      status: s.status,
      priority: s.priority,
      responseTime: s.responseTime,
      consecutiveFailures: s.consecutiveFailures,
      lastCheck: s.lastCheck,
      lastSuccess: s.lastSuccess,
    }));
  }

  // è®¾ç½®æœåŠ¡å˜æ›´å›è°ƒ
  onServiceChange(callback: (service: AIServiceConfig) => void) {
    this.onServiceChangeCallback = callback;
  }
}

// åˆå§‹åŒ–æœåŠ¡ç®¡ç†å™¨
const aiServiceManager = new AIServiceManager(AI_SERVICES);

// å¯åŠ¨å¥åº·æ£€æŸ¥ï¼ˆæ¯30ç§’ï¼‰
aiServiceManager.startHealthCheck(60000 * 60 * 24);

// ç›‘å¬æœåŠ¡åˆ‡æ¢
aiServiceManager.onServiceChange((service) => {
  console.log(`ğŸ“¡ å½“å‰ä½¿ç”¨æœåŠ¡: ${service.name}`);
});

// åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆKey ç¡¬ç¼–ç ä»…ç”¨äºæµ‹è¯•ï¼Œç”Ÿäº§ç¯å¢ƒå¿…é¡»ç§»é™¤ï¼ï¼‰
// const openai = new OpenAI({
//   apiKey: 'sk-MhhXBfjcOEJb5eOOjBb0bn8P0qcLaQFE0sVOZTCb5OradbEd', // æ›¿æ¢ä¸ºä½ çš„å®é™… Key
//   baseURL: 'https://api.chatanywhere.tech/v1',
//   dangerouslyAllowBrowser: true, // æ˜ç¡®å…è®¸æµè§ˆå™¨ç¯å¢ƒï¼ˆä»…é™å¼€å‘ï¼‰
// });

const tools = Array.from(toolsMap.values()).map(({ fun, ...item }) => {
  const jsonSchema = zodToJsonSchema(item.function.parameters);
  return {
    type: item.type,
    function: {
      name: item.function.name,
      description: item.function.description,
      parameters: {
        type: 'object',
        properties: jsonSchema.properties,
        required: jsonSchema.required,
      },
    },
  };
});

// å¯¹è¯å‡½æ•°
export const chatWithGPT = async (
  messages: any,
  onChunk?: (chunk: string) => void, // å›è°ƒå‡½æ•°ï¼Œç”¨äºå¤„ç†æ¯ä¸ªæ•°æ®å—
  onComplete?: (fullResponse: string) => void, // å®Œæˆæ—¶çš„å›è°ƒ
  onError?: (error: any) => void, // é”™è¯¯å¤„ç†å›è°ƒ
  onServiceSwitch?: (serviceName: string) => void, // æ–°å¢ï¼šæœåŠ¡åˆ‡æ¢å›è°ƒ
) => {
  const externalContent =
    'æ™ºæ±‡äº‘èˆŸï¼ˆWisdom Arkï¼‰æ˜¯ä¸€ä¸ªä¾¿äºç”¨æˆ·æŸ¥è¯¢ã€å­¦ä¹ ã€ä½¿ç”¨çš„å‰ç«¯çŸ¥è¯†åº“';
  const recentMessages = messages.slice(-5);
  const newMessages = [
    {
      role: 'system',
      content: `
        ## è§’è‰²
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯å¯¼å¸ˆï¼Œä½ æœ€æ“…é•¿Reactã€Webpackã€Antdè¿™äº›å‰ç«¯æ¡†æ¶ï¼Œä½ èƒ½å¤Ÿç”±æµ…å…¥æ·±çš„å›ç­”ç”¨æˆ·å…³äºå‰ç«¯çš„é—®é¢˜
        ## å‚è€ƒå†…å®¹
        ${externalContent}
        ## è¾“å‡ºè§„èŒƒ
        - å…³äºä»£ç é—®é¢˜ï¼Œä½ èƒ½å¤ŸæŒ‰ç…§"è®¾è®¡æ€è·¯"ã€"ä»£ç å®ç°"ä¸¤ä¸ªç»´åº¦æ¥å›ç­”
        - è·Ÿç¼–ç¨‹æ— å…³çš„é—®é¢˜ä½ å¯ä»¥æ‹’ç»å›ç­”
        `,
    },
    ...recentMessages,
  ];

  // å°è¯•æ‰€æœ‰å¯ç”¨AI
  const attemptedServices = new Set<string>();
  let lastError: any = null;

  while (true) {
    const currentService = aiServiceManager.getCurrentService();

    if (!currentService) {
      const error = new Error('æ‰€æœ‰ AI æœåŠ¡éƒ½ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•');
      onError?.(error);
      throw error;
    }

    // é¿å…é‡å¤å°è¯•åŒä¸€æœåŠ¡
    if (attemptedServices.has(currentService.id)) {
      break;
    }
    attemptedServices.add(currentService.id);
    try {
      console.log(`ğŸš€ ä½¿ç”¨ ${currentService.name} å‘é€è¯·æ±‚...`);
      onServiceSwitch?.(currentService.name);

      const response = await currentService.client.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: newMessages,
        stream: true, // å¯ç”¨æµå¼å“åº”
        temperature: 0.7,
        tools: tools as any,
      });

      let fullResponse = '';
      const toolCalls: any[] = [];

      // å¤„ç†æµå¼æ•°æ®
      for await (const chunk of response) {
        const delta = chunk.choices[0]?.delta;

        if (delta?.content) {
          // æ™®é€šæ–‡æœ¬å†…å®¹
          const content = delta.content;
          fullResponse += content;
          // å®æ—¶å›è°ƒï¼Œç”¨äºUIæ›´æ–°
          onChunk?.(content);
        }

        if (delta?.tool_calls) {
          // å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆæµå¼æ¨¡å¼ä¸‹å·¥å…·è°ƒç”¨å¯èƒ½åˆ†å¤šä¸ªchunkï¼‰
          delta.tool_calls.forEach((toolCall: any, index: number) => {
            if (!toolCalls[index]) {
              toolCalls[index] = {
                id: toolCall.id,
                type: toolCall.type,
                function: { name: '', arguments: '' },
              };
            }

            if (toolCall.function?.name) {
              toolCalls[index].function.name += toolCall.function.name;
            }

            if (toolCall.function?.arguments) {
              toolCalls[index].function.arguments +=
                toolCall.function.arguments;
            }
          });
        }

        // æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if (
          chunk.choices[0]?.finish_reason === 'stop' ||
          chunk.choices[0]?.finish_reason === 'tool_calls'
        ) {
          break;
        }
      }

      // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå¤„ç†å·¥å…·è°ƒç”¨
      if (toolCalls.length > 0) {
        const toolResponses = await Promise.all(
          toolCalls.map(async (toolCall) => {
            const toolId = toolCall.id;
            if (!toolId) {
              return {
                role: 'tool',
                content: 'æœªæ‰¾åˆ°å¯¹åº”å·¥å…·',
                tool_call_id: toolId,
              };
            }

            const functionName = toolCall.function.name;
            const tool = toolsMap.get(functionName);

            if (tool) {
              try {
                const args = JSON.parse(toolCall.function.arguments);
                const result = await tool.fun(args);

                return {
                  role: 'tool',
                  content:
                    typeof result === 'string'
                      ? result
                      : JSON.stringify(result),
                  tool_call_id: toolId,
                };
              } catch (error) {
                console.error('å·¥å…·æ‰§è¡Œå¤±è´¥:', error);
                return {
                  role: 'tool',
                  content: 'å·¥å…·æ‰§è¡Œå¤±è´¥',
                  tool_call_id: toolId,
                };
              }
            } else {
              return {
                role: 'tool',
                content: 'æœªæ‰¾åˆ°å¯¹åº”å·¥å…·',
                tool_call_id: toolId,
              };
            }
          }),
        );

        const toolResult = JSON.parse(toolResponses[0].content).content;
        onComplete?.(toolResult);
        return toolResult;
      }

      // æ ‡è®°æœåŠ¡æˆåŠŸ
      aiServiceManager.markServiceSuccess(currentService.id);

      onComplete?.(fullResponse);
      return fullResponse;
    } catch (error) {
      //   console.error('OpenAI API Error:', error);
      //   return 'å‘ç”Ÿé”™è¯¯ï¼Œè¯·é‡è¯•';
      lastError = error;
      console.error(`âŒ ${currentService.name} è¯·æ±‚å¤±è´¥:`, error);

      // æ ‡è®°æœåŠ¡å¤±è´¥
      aiServiceManager.markServiceFailure(currentService.id);

      // å°è¯•åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæœåŠ¡
      const nextService = aiServiceManager.selectBestService();

      if (!nextService || attemptedServices.has(nextService.id)) {
        // æ²¡æœ‰æ›´å¤šå¯ç”¨æœåŠ¡
        break;
      }

      console.log(`ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æœåŠ¡: ${nextService.name}`);
      await new Promise((resolve) => setTimeout(resolve, 1000)); // ç­‰å¾…1ç§’åé‡è¯•
    }
  }
  // æ‰€æœ‰æœåŠ¡éƒ½å¤±è´¥äº†
  const error = lastError || new Error('æ‰€æœ‰ AI æœåŠ¡éƒ½å¤±è´¥äº†');
  onError?.(error);
  return 'å‘ç”Ÿé”™è¯¯ï¼Œæ‰€æœ‰ AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•';
};

// ==================== æ— é™åˆ¶å¯¹è¯å‡½æ•°ï¼ˆä¸æ·»åŠ ç³»ç»Ÿçº¦æŸã€ä¸ä½¿ç”¨å·¥å…·ï¼‰ ====================
export interface ChatRawOptions {
  model?: string;
  temperature?: number;
  stream?: boolean;
  onChunk?: (chunk: string) => void;
  onComplete?: (fullResponse: string) => void;
  onError?: (error: any) => void;
  onServiceSwitch?: (serviceName: string) => void;
}

export const chatRaw = async (
  messages: { role: 'system' | 'user' | 'assistant'; content: string }[],
  options: ChatRawOptions = {},
) => {
  const {
    model,
    temperature = 0.7,
    stream = false,
    onChunk,
    onComplete,
    onError,
    onServiceSwitch,
  } = options;

  const attempted = new Set<string>();
  let lastErr: any = null;

  while (true) {
    const svc = aiServiceManager.getCurrentService();
    if (!svc) {
      const err = new Error('æ‰€æœ‰ AI æœåŠ¡éƒ½ä¸å¯ç”¨');
      onError?.(err);
      throw err;
    }
    if (attempted.has(svc.id)) break;
    attempted.add(svc.id);

    try {
      onServiceSwitch?.(svc.name);
      const usedModel = model || svc.model || 'gpt-4o-mini';

      // éæµå¼
      if (!stream) {
        const res = await svc.client.chat.completions.create({
          model: usedModel,
          messages,
          temperature,
        });
        const content = res.choices?.[0]?.message?.content || '';
        aiServiceManager.markServiceSuccess(svc.id);
        onComplete?.(content);
        return content;
      }

      // æµå¼
      const res = await svc.client.chat.completions.create({
        model: usedModel,
        messages,
        temperature,
        stream: true,
      });

      let full = '';
      for await (const chunk of res) {
        const delta = chunk.choices?.[0]?.delta;
        const txt = delta?.content || '';
        if (txt) {
          full += txt;
          onChunk?.(txt);
        }
        if (chunk.choices?.[0]?.finish_reason) break;
      }
      aiServiceManager.markServiceSuccess(svc.id);
      onComplete?.(full);
      return full;
    } catch (e) {
      lastErr = e;
      aiServiceManager.markServiceFailure(svc.id);
      const next = aiServiceManager.selectBestService();
      if (!next || attempted.has(next.id)) break;
      await new Promise((r) => setTimeout(r, 500));
    }
  }

  onError?.(lastErr);
  return '';
};

export const chatInEditor = async (content: {
  prefix: string;
  suffix: string;
}) => {
  const { prefix, suffix } = content;
  const client = new OpenAI({
    baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    apiKey: 'sk-da6f76fe6f8e4bc2871be0c57ffa3201',
    dangerouslyAllowBrowser: true,
  });

  const completion = await client.completions.create({
    model: 'qwen2.5-coder-7b-instruct',
    prompt: `<|fim_prefix|>${prefix}<|fim_suffix|>${suffix}<|fim_middle|>`,
  });
  console.log(completion.choices[0], 'completion.choices[0]');

  return completion.choices[0].text;

  return `
   let timer = null;
 return function (fn, time) {
   if(timer){
     clearTimeout(timer);
   }
   timer = setTimeout(() => {
     fn.apply(this, arguments);
   },time)
 }  
}

// è°ƒç”¨
const debouncedScrollHandler = debounce(function() {
  console.log('æ»šåŠ¨äº‹ä»¶è§¦å‘');
}, 300);

window.addEventListener('scroll', debouncedScrollHandler);`;
};
