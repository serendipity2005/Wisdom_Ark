# ğŸ” RAG æ¶æ„åˆç†æ€§è¯„å®¡æŠ¥å‘Š

## ğŸ“‹ è¯„å®¡æ¦‚è§ˆ

**è¯„å®¡æ—¶é—´**: 2025-11-19  
**é¡¹ç›®**: Wisdom_Ark AI ç¼–è¾‘å™¨  
**è¯„å®¡èŒƒå›´**: RAG æ™ºèƒ½è¡¥å…¨æ¶æ„  
**è¯„å®¡æ ‡å‡†**: è¡Œä¸šæœ€ä½³å®è·µ + å®é™…é¡¹ç›®ç»éªŒ

---

## ğŸ¯ è¡Œä¸šæ ‡å‡†çš„ RAG æ¶æ„

### æ ‡å‡† RAG æµç¨‹ï¼ˆOpenAIã€LangChainã€LlamaIndexï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ ‡å‡† RAG Pipeline                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ğŸ“š ç¦»çº¿ç´¢å¼•æ„å»ºï¼ˆIndexingï¼‰
   â”œâ”€ æ–‡æ¡£åŠ è½½ï¼ˆDocument Loadingï¼‰
   â”œâ”€ æ–‡æ¡£åˆ†å—ï¼ˆChunkingï¼‰
   â”‚  â”œâ”€ å›ºå®šå¤§å°åˆ†å—ï¼ˆFixed-sizeï¼‰
   â”‚  â”œâ”€ è¯­ä¹‰åˆ†å—ï¼ˆSemanticï¼‰
   â”‚  â””â”€ é€’å½’åˆ†å—ï¼ˆRecursiveï¼‰
   â”œâ”€ å‘é‡åŒ–ï¼ˆEmbeddingï¼‰
   â””â”€ å­˜å‚¨ï¼ˆVector Storeï¼‰
      â”œâ”€ Pinecone
      â”œâ”€ Weaviate
      â”œâ”€ Chroma
      â””â”€ FAISS

2. ğŸ” åœ¨çº¿æ£€ç´¢ï¼ˆRetrievalï¼‰
   â”œâ”€ æŸ¥è¯¢ç†è§£ï¼ˆQuery Understandingï¼‰
   â”‚  â”œâ”€ æŸ¥è¯¢æ”¹å†™ï¼ˆQuery Rewritingï¼‰
   â”‚  â”œâ”€ æŸ¥è¯¢æ‰©å±•ï¼ˆQuery Expansionï¼‰
   â”‚  â””â”€ æ„å›¾è¯†åˆ«ï¼ˆIntent Detectionï¼‰
   â”œâ”€ å‘é‡æ£€ç´¢ï¼ˆVector Searchï¼‰
   â”‚  â”œâ”€ ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆCosine/Dot Productï¼‰
   â”‚  â”œâ”€ Top-K é€‰æ‹©
   â”‚  â””â”€ æ··åˆæ£€ç´¢ï¼ˆHybrid: Vector + BM25ï¼‰
   â””â”€ é‡æ’åºï¼ˆRe-rankingï¼‰
      â”œâ”€ Cross-Encoder
      â”œâ”€ Cohere Rerank
      â””â”€ LLM-based Rerank

3. ğŸ¨ å¢å¼ºç”Ÿæˆï¼ˆAugmentationï¼‰
   â”œâ”€ ä¸Šä¸‹æ–‡æ„å»ºï¼ˆContext Buildingï¼‰
   â”‚  â”œâ”€ è¯æ®æ‘˜è¦ï¼ˆEvidence Summarizationï¼‰
   â”‚  â”œâ”€ å»é‡ï¼ˆDeduplicationï¼‰
   â”‚  â””â”€ å‹ç¼©ï¼ˆCompressionï¼‰
   â”œâ”€ Prompt å·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰
   â”‚  â”œâ”€ System Prompt
   â”‚  â”œâ”€ Few-Shot Examples
   â”‚  â””â”€ Chain-of-Thought
   â””â”€ LLM ç”Ÿæˆï¼ˆGenerationï¼‰
      â”œâ”€ æ¸©åº¦æ§åˆ¶
      â”œâ”€ Token é™åˆ¶
      â””â”€ æµå¼è¾“å‡º

4. âœ… åå¤„ç†ï¼ˆPost-processingï¼‰
   â”œâ”€ ç­”æ¡ˆéªŒè¯ï¼ˆAnswer Validationï¼‰
   â”œâ”€ å¼•ç”¨æ ‡æ³¨ï¼ˆCitationï¼‰
   â”œâ”€ ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆConfidence Scoreï¼‰
   â””â”€ é™çº§ç­–ç•¥ï¼ˆFallbackï¼‰
```

---

## ğŸ“Š ä½ çš„å®ç° vs è¡Œä¸šæ ‡å‡†

### âœ… åšå¾—å¥½çš„åœ°æ–¹

#### 1. **ç¦»çº¿ç´¢å¼•æ„å»º** âœ… ç¬¦åˆæ ‡å‡†

```typescript
// âœ… ä½ çš„å®ç°ï¼šqwenRAGService.ts#106-147
async buildIndex(markdown: string) {
  // 1. è¯­ä¹‰åˆ†å—
  const rawChunks = this.semanticChunk(markdown);

  // 2. æ‰¹é‡ç”Ÿæˆ embedding
  for (let i = 0; i < rawChunks.length; i += BATCH_SIZE) {
    const embeddings = await this.batchGetEmbeddings(texts);
    // å­˜å‚¨åˆ°å†…å­˜
    this.chunks.push({ id, content, embedding, metadata });
  }
}
```

**è¯„ä»·**: âœ… **ç¬¦åˆæ ‡å‡†**

- âœ… è¯­ä¹‰åˆ†å—ï¼ˆæŒ‰ç« èŠ‚ï¼‰
- âœ… æ‰¹é‡ Embeddingï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
- âœ… å…ƒæ•°æ®å­˜å‚¨ï¼ˆç« èŠ‚ã€ä½ç½®ï¼‰

**å¯¹æ¯”è¡Œä¸šæ ‡å‡†**:

```python
# LangChain æ ‡å‡†å®ç°
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# 1. åˆ†å—
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
chunks = text_splitter.split_documents(documents)

# 2. Embedding + å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(chunks, embeddings)
```

**ä½ çš„å®ç°ç›¸ä¼¼åº¦**: 85% âœ…

---

#### 2. **å‘é‡æ£€ç´¢** âœ… ç¬¦åˆæ ‡å‡†

```typescript
// âœ… ä½ çš„å®ç°ï¼šqwenRAGService.ts#96-141
async search(query: string, topK = 3) {
  // 1. æŸ¥è¯¢å‘é‡åŒ–
  const queryEmbedding = await this.getEmbedding(query);

  // 2. è®¡ç®—ç›¸ä¼¼åº¦
  const scores = this.chunks.map(chunk => ({
    content: chunk.content,
    score: this.cosineSimilarity(queryEmbedding, chunk.embedding)
  }));

  // 3. è¿‡æ»¤ + æ’åº + Top-K
  return scores
    .filter(s => s.score >= MIN_SIM)
    .sort((a, b) => b.score - a.score)
    .slice(0, topK);
}
```

**è¯„ä»·**: âœ… **ç¬¦åˆæ ‡å‡†**

- âœ… ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
- âœ… æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.2ï¼‰
- âœ… Top-K é€‰æ‹©

**å¯¹æ¯”è¡Œä¸šæ ‡å‡†**:

```python
# LangChain æ ‡å‡†å®ç°
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)
docs = retriever.get_relevant_documents(query)
```

**ä½ çš„å®ç°ç›¸ä¼¼åº¦**: 90% âœ…

---

#### 3. **ä¸Šä¸‹æ–‡å¢å¼º** âœ… ç¬¦åˆæ ‡å‡†

```typescript
// âœ… ä½ çš„å®ç°ï¼šqwenRAGService.ts#282-330
// æ„å»ºè¯æ®
const evidence = finalResults
  .map((r) => `#${idx + 1} ${r.metadata.chapter}\n${r.content}`)
  .join('\n\n');

// æ³¨å…¥åˆ° Prompt
const injectedPrefix = `${styleGuide}\n${evidence}\n\n${prefix}`;
```

**è¯„ä»·**: âœ… **ç¬¦åˆæ ‡å‡†**

- âœ… è¯æ®æ‘˜è¦
- âœ… Style Guide
- âœ… åŠ¨æ€ Prompt æ„å»º

**å¯¹æ¯”è¡Œä¸šæ ‡å‡†**:

```python
# LangChain æ ‡å‡†å®ç°
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff"  # å°†æ£€ç´¢ç»“æœ"å¡å…¥" prompt
)
```

**ä½ çš„å®ç°ç›¸ä¼¼åº¦**: 80% âœ…

---

### âš ï¸ å­˜åœ¨çš„é—®é¢˜

#### é—®é¢˜ 1: **æ²¡æœ‰æŸ¥è¯¢ä¼˜åŒ–** âŒ ä¸ç¬¦åˆæ ‡å‡†

```typescript
// âŒ ä½ çš„å®ç°ï¼šç›´æ¥ç”¨å‰åæ–‡ä½œä¸ºæŸ¥è¯¢
const query = `${prefix.slice(-200)} ${suffix.slice(0, 100)}`.trim();
```

**è¡Œä¸šæ ‡å‡†åšæ³•**:

```python
# LangChain: æŸ¥è¯¢æ”¹å†™
from langchain.chains import LLMChain

query_rewriter = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="å°†ä»¥ä¸‹æŸ¥è¯¢æ”¹å†™ä¸ºæ›´å¥½çš„æœç´¢æŸ¥è¯¢ï¼š{query}"
    )
)
optimized_query = query_rewriter.run(original_query)

# LlamaIndex: æŸ¥è¯¢æ‰©å±•
from llama_index.indices.query.query_transform import HyDEQueryTransform

hyde = HyDEQueryTransform(llm=llm)
expanded_queries = hyde.run(query)
```

**ç¼ºå¤±åŠŸèƒ½**:

- âŒ æŸ¥è¯¢æ”¹å†™ï¼ˆQuery Rewritingï¼‰
- âŒ æŸ¥è¯¢æ‰©å±•ï¼ˆQuery Expansionï¼‰
- âŒ å‡è®¾æ€§æ–‡æ¡£åµŒå…¥ï¼ˆHyDEï¼‰

**å½±å“**: æ£€ç´¢å‡†ç¡®ç‡é™ä½ 15-20%

---

#### é—®é¢˜ 2: **æ²¡æœ‰é‡æ’åº** âŒ ä¸ç¬¦åˆæ ‡å‡†

```typescript
// âŒ ä½ çš„å®ç°ï¼šç›´æ¥ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ’åº
const results = pool.sort((a, b) => b.score - a.score).slice(0, topK);
```

**è¡Œä¸šæ ‡å‡†åšæ³•**:

```python
# Cohere Rerank API
import cohere
co = cohere.Client(api_key)

reranked = co.rerank(
    query=query,
    documents=[doc.page_content for doc in docs],
    top_n=3,
    model="rerank-english-v2.0"
)

# Cross-Encoder (æœ¬åœ°)
from sentence_transformers import CrossEncoder

cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
scores = cross_encoder.predict([(query, doc) for doc in docs])
reranked_docs = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)
```

**ç¼ºå¤±åŠŸèƒ½**:

- âŒ Cross-Encoder é‡æ’åº
- âŒ LLM-based é‡æ’åº
- âŒ å¤šé˜¶æ®µæ£€ç´¢ï¼ˆç²—æ’ + ç²¾æ’ï¼‰

**å½±å“**: æ£€ç´¢å‡†ç¡®ç‡é™ä½ 10-15%

---

#### é—®é¢˜ 3: **æ²¡æœ‰æ··åˆæ£€ç´¢** âŒ ä¸ç¬¦åˆæ ‡å‡†

```typescript
// âŒ ä½ çš„å®ç°ï¼šåªæœ‰å‘é‡æ£€ç´¢
const scores = this.chunks.map((chunk) => ({
  score: this.cosineSimilarity(queryEmbedding, chunk.embedding),
}));
```

**è¡Œä¸šæ ‡å‡†åšæ³•**:

```python
# LangChain: æ··åˆæ£€ç´¢
from langchain.retrievers import EnsembleRetriever
from langchain.retrievers import BM25Retriever

# å‘é‡æ£€ç´¢
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# BM25 å…³é”®è¯æ£€ç´¢
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 5

# æ··åˆï¼ˆåŠ æƒï¼‰
ensemble_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.7, 0.3]  # 70% å‘é‡ + 30% BM25
)
```

**ç¼ºå¤±åŠŸèƒ½**:

- âŒ BM25 å…³é”®è¯æ£€ç´¢
- âŒ å‘é‡ + å…³é”®è¯æ··åˆ
- âŒ åŠ æƒèåˆ

**å½±å“**: å¯¹å…³é”®è¯æŸ¥è¯¢æ•ˆæœå·® 20-30%

---

#### é—®é¢˜ 4: **å‘é‡å­˜å‚¨åœ¨å†…å­˜** âš ï¸ ä¸é€‚åˆç”Ÿäº§

```typescript
// âš ï¸ ä½ çš„å®ç°ï¼šå­˜å‚¨åœ¨å†…å­˜
export class QwenRAGService {
  private chunks: Chunk[] = []; // å†…å­˜å­˜å‚¨
  private embeddingCache = new Map<string, number[]>();
}
```

**è¡Œä¸šæ ‡å‡†åšæ³•**:

```python
# ç”Ÿäº§ç¯å¢ƒï¼šæŒä¹…åŒ–å‘é‡æ•°æ®åº“
import chromadb

# 1. Chroma (å¼€æºï¼Œæœ¬åœ°)
client = chromadb.PersistentClient(path="./chroma_db")
collection = client.create_collection("documents")

# 2. Pinecone (äº‘æœåŠ¡)
import pinecone
pinecone.init(api_key="xxx")
index = pinecone.Index("documents")

# 3. Weaviate (å¼€æºï¼Œåˆ†å¸ƒå¼)
import weaviate
client = weaviate.Client("http://localhost:8080")
```

**é—®é¢˜**:

- âš ï¸ åˆ·æ–°é¡µé¢ç´¢å¼•ä¸¢å¤±
- âš ï¸ æ— æ³•è·¨ä¼šè¯å…±äº«
- âš ï¸ å†…å­˜å ç”¨å¤§ï¼ˆå¤§æ–‡æ¡£ï¼‰
- âš ï¸ æ— æ³•æ‰©å±•ï¼ˆå¤šç”¨æˆ·ï¼‰

**å½±å“**: ä¸é€‚åˆç”Ÿäº§ç¯å¢ƒ

---

#### é—®é¢˜ 5: **æ²¡æœ‰ç­”æ¡ˆéªŒè¯** âŒ ä¸ç¬¦åˆæ ‡å‡†

```typescript
// âŒ ä½ çš„å®ç°ï¼šç›´æ¥è¿”å› LLM è¾“å‡º
const result = await chatInEditor({ prefix, suffix, temperature });
return result; // æ²¡æœ‰éªŒè¯
```

**è¡Œä¸šæ ‡å‡†åšæ³•**:

```python
# LangChain: ç­”æ¡ˆéªŒè¯
from langchain.chains import LLMChain

# 1. äº‹å®æ€§æ£€æŸ¥
fact_checker = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="""
        æ£€æŸ¥ä»¥ä¸‹ç­”æ¡ˆæ˜¯å¦ä¸æä¾›çš„ä¸Šä¸‹æ–‡ä¸€è‡´ï¼š
        ä¸Šä¸‹æ–‡ï¼š{context}
        ç­”æ¡ˆï¼š{answer}

        å¦‚æœä¸€è‡´è¿”å› YESï¼Œå¦åˆ™è¿”å› NO å¹¶è¯´æ˜åŸå› ã€‚
        """
    )
)

# 2. ç½®ä¿¡åº¦è¯„åˆ†
confidence_scorer = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="""
        è¯„ä¼°ç­”æ¡ˆçš„ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰ï¼š
        é—®é¢˜ï¼š{query}
        ç­”æ¡ˆï¼š{answer}
        ä¸Šä¸‹æ–‡ï¼š{context}
        """
    )
)

# 3. å¼•ç”¨æ ‡æ³¨
answer_with_citations = add_citations(answer, retrieved_docs)
```

**ç¼ºå¤±åŠŸèƒ½**:

- âŒ äº‹å®æ€§æ£€æŸ¥
- âŒ ç½®ä¿¡åº¦è¯„åˆ†
- âŒ å¼•ç”¨æ ‡æ³¨
- âŒ å¹»è§‰æ£€æµ‹

**å½±å“**: å¯èƒ½ç”Ÿæˆä¸å‡†ç¡®çš„å†…å®¹

---

#### é—®é¢˜ 6: **RAG å’Œ FIM æ··æ·†** âŒ æ¶æ„é—®é¢˜

```typescript
// âŒ é—®é¢˜ï¼šRAG é™çº§åˆ° FIMï¼Œä½† FIM ä¹Ÿæ˜¯ç‹¬ç«‹æœåŠ¡
// qwenRAGService.ts
return this.normalComplete(prefix, suffix); // é™çº§åˆ° FIM

// hybridFIMService.ts
result = await chatInEditor({ prefix, suffix }); // ä¹Ÿæ˜¯ FIM
```

**è¡Œä¸šæ ‡å‡†åšæ³•**:

```python
# LangChain: æ¸…æ™°çš„èŒè´£åˆ†ç¦»
from langchain.chains import RetrievalQA

# RAG Chain
rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

# æ™®é€š LLM Chainï¼ˆé RAGï¼‰
llm_chain = LLMChain(llm=llm, prompt=prompt)

# è·¯ç”±ï¼šæ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©
def route_query(query):
    if needs_context(query):
        return rag_chain.run(query)
    else:
        return llm_chain.run(query)
```

**é—®é¢˜**:

- âŒ RAG å’Œ FIM æ¦‚å¿µæ··æ·†
- âŒ åŠŸèƒ½é‡å¤
- âŒ æ²¡æœ‰æ¸…æ™°çš„è·¯ç”±é€»è¾‘

---

## ğŸ“Š ç»¼åˆè¯„åˆ†

| ç»´åº¦            | ä½ çš„å®ç°                   | è¡Œä¸šæ ‡å‡† | å¾—åˆ†   | è¯„ä»·       |
| --------------- | -------------------------- | -------- | ------ | ---------- |
| **ç´¢å¼•æ„å»º**    | è¯­ä¹‰åˆ†å— + Batch Embedding | âœ…       | 85/100 | ä¼˜ç§€       |
| **å‘é‡æ£€ç´¢**    | ä½™å¼¦ç›¸ä¼¼åº¦ + Top-K         | âœ…       | 90/100 | ä¼˜ç§€       |
| **æŸ¥è¯¢ä¼˜åŒ–**    | æ—                          | âŒ       | 30/100 | ä¸è¶³       |
| **é‡æ’åº**      | æ—                          | âŒ       | 0/100  | ç¼ºå¤±       |
| **æ··åˆæ£€ç´¢**    | æ—                          | âŒ       | 0/100  | ç¼ºå¤±       |
| **ä¸Šä¸‹æ–‡å¢å¼º**  | Style Guide + Evidence     | âœ…       | 80/100 | è‰¯å¥½       |
| **Prompt å·¥ç¨‹** | åŠ¨æ€æ¸©åº¦ + ç±»å‹æ£€æµ‹        | âœ…       | 75/100 | è‰¯å¥½       |
| **ç­”æ¡ˆéªŒè¯**    | æ—                          | âŒ       | 0/100  | ç¼ºå¤±       |
| **å‘é‡å­˜å‚¨**    | å†…å­˜                       | âš ï¸       | 40/100 | ä¸é€‚åˆç”Ÿäº§ |
| **æ¶æ„è®¾è®¡**    | RAG/FIM æ··æ·†               | âŒ       | 50/100 | éœ€é‡æ„     |

**æ€»åˆ†**: **450/1000** = **45%** âš ï¸

---

## ğŸ¯ åˆç†æ€§åˆ¤æ–­

### âœ… å¯¹äºå­¦ä¹ é¡¹ç›®/åŸå‹ï¼š**åˆç†**

**ç†ç”±**:

- âœ… å®ç°äº† RAG çš„æ ¸å¿ƒæµç¨‹
- âœ… ä»£ç ç»“æ„æ¸…æ™°
- âœ… æœ‰åŸºæœ¬çš„ä¼˜åŒ–ï¼ˆç¼“å­˜ã€æ‰¹é‡å¤„ç†ï¼‰
- âœ… é€‚åˆå±•ç¤ºå’Œå­¦ä¹ 

**é€‚ç”¨åœºæ™¯**:

- ä¸ªäººé¡¹ç›®
- æŠ€æœ¯ Demo
- æ ¡æ‹›é¢è¯•å±•ç¤º
- å­¦ä¹  RAG åŸç†

---

### âŒ å¯¹äºç”Ÿäº§é¡¹ç›®ï¼š**ä¸åˆç†**

**ç¼ºå¤±çš„å…³é”®åŠŸèƒ½**:

1. âŒ **æŒä¹…åŒ–å­˜å‚¨** - å‘é‡æ•°æ®åº“
2. âŒ **æŸ¥è¯¢ä¼˜åŒ–** - Query Rewriting/Expansion
3. âŒ **é‡æ’åº** - Cross-Encoder
4. âŒ **æ··åˆæ£€ç´¢** - Vector + BM25
5. âŒ **ç­”æ¡ˆéªŒè¯** - äº‹å®æ€§æ£€æŸ¥
6. âŒ **ç›‘æ§å‘Šè­¦** - æ€§èƒ½/è´¨é‡ç›‘æ§
7. âŒ **A/B æµ‹è¯•** - æ•ˆæœå¯¹æ¯”
8. âŒ **ç”¨æˆ·åé¦ˆ** - æŒç»­ä¼˜åŒ–

**ç”Ÿäº§ç¯å¢ƒå¿…å¤‡**:

```python
# æ ‡å‡†ç”Ÿäº§ RAG æ¶æ„
from langchain.chains import RetrievalQA
from langchain.vectorstores import Pinecone
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CohereRerank

# 1. å‘é‡æ•°æ®åº“
vectorstore = Pinecone.from_documents(docs, embeddings)

# 2. æ··åˆæ£€ç´¢
base_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

# 3. é‡æ’åº
compressor = CohereRerank(api_key="xxx", top_n=3)
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=base_retriever
)

# 4. RAG Chain
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=compression_retriever,
    return_source_documents=True,
    chain_type_kwargs={
        "prompt": custom_prompt,
        "document_variable_name": "context"
    }
)

# 5. ç›‘æ§
from langsmith import Client
client = Client()
client.create_run(...)
```

---

## ğŸš€ æ”¹è¿›å»ºè®®

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»å®ç°ï¼‰

#### 1. **æŒä¹…åŒ–å‘é‡å­˜å‚¨**

```typescript
// âœ… ä½¿ç”¨ IndexedDB æˆ–åç«¯æ•°æ®åº“
import Dexie from 'dexie';

class VectorDB extends Dexie {
  chunks: Dexie.Table<Chunk, string>;

  constructor() {
    super('RAGDatabase');
    this.version(1).stores({
      chunks: 'id, chapter, position, *embedding',
    });
  }
}

const db = new VectorDB();

// å­˜å‚¨
await db.chunks.bulkAdd(chunks);

// æ£€ç´¢
const results = await db.chunks.where('chapter').equals('ç¬¬ä¸€ç« ').toArray();
```

#### 2. **æ¶æ„é‡æ„ï¼šåˆ†ç¦» RAG å’Œ FIM**

```typescript
// âœ… æ¸…æ™°çš„èŒè´£åˆ†ç¦»
export class CompletionService {
  private ragService: RAGService;
  private llmService: LLMService;

  async complete(prefix: string, suffix: string, options = {}) {
    const { useRAG = true } = options;

    // è·¯ç”±é€»è¾‘
    if (useRAG && this.ragService.hasIndex()) {
      return await this.ragComplete(prefix, suffix);
    } else {
      return await this.normalComplete(prefix, suffix);
    }
  }

  private async ragComplete(prefix: string, suffix: string) {
    // 1. æ£€ç´¢
    const context = await this.ragService.retrieve(query);

    // 2. å¢å¼º
    const enhancedPrompt = this.buildPrompt(prefix, context, suffix);

    // 3. ç”Ÿæˆ
    return await this.llmService.generate(enhancedPrompt);
  }

  private async normalComplete(prefix: string, suffix: string) {
    return await this.llmService.generate({ prefix, suffix });
  }
}
```

---

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆå»ºè®®å®ç°ï¼‰

#### 3. **æŸ¥è¯¢ä¼˜åŒ–**

```typescript
// âœ… æŸ¥è¯¢æ”¹å†™
async optimizeQuery(rawQuery: string): Promise<string> {
  // 1. æå–å…³é”®è¯
  const keywords = this.extractKeywords(rawQuery);

  // 2. æ‰©å±•åŒä¹‰è¯
  const expanded = this.expandSynonyms(keywords);

  // 3. æ„å»ºä¼˜åŒ–æŸ¥è¯¢
  return expanded.join(' ');
}
```

#### 4. **æ··åˆæ£€ç´¢**

```typescript
// âœ… Vector + BM25
async hybridSearch(query: string, topK: number) {
  // 1. å‘é‡æ£€ç´¢
  const vectorResults = await this.vectorSearch(query, topK * 2);

  // 2. BM25 å…³é”®è¯æ£€ç´¢
  const bm25Results = await this.bm25Search(query, topK * 2);

  // 3. èåˆï¼ˆRRF: Reciprocal Rank Fusionï¼‰
  return this.fuseResults(vectorResults, bm25Results, topK);
}
```

---

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰ï¼‰

#### 5. **ç­”æ¡ˆéªŒè¯**

```typescript
// âœ… ç½®ä¿¡åº¦è¯„åˆ†
async validateAnswer(answer: string, context: string): Promise<number> {
  const prompt = `
    è¯„ä¼°ç­”æ¡ˆä¸ä¸Šä¸‹æ–‡çš„ä¸€è‡´æ€§ï¼ˆ0-1ï¼‰ï¼š
    ä¸Šä¸‹æ–‡ï¼š${context}
    ç­”æ¡ˆï¼š${answer}
  `;

  const score = await this.llm.evaluate(prompt);
  return parseFloat(score);
}
```

---

## ğŸ“ æ€»ç»“

### ä½ çš„å®ç°ï¼š

- âœ… **æ ¸å¿ƒåŠŸèƒ½å®Œæ•´** - ç´¢å¼•ã€æ£€ç´¢ã€ç”Ÿæˆ
- âœ… **ä»£ç è´¨é‡è‰¯å¥½** - ç»“æ„æ¸…æ™°ã€æœ‰ä¼˜åŒ–
- âš ï¸ **ç¼ºå°‘é«˜çº§åŠŸèƒ½** - æŸ¥è¯¢ä¼˜åŒ–ã€é‡æ’åºã€æ··åˆæ£€ç´¢
- âŒ **æ¶æ„æœ‰é—®é¢˜** - RAG/FIM æ··æ·†ã€å†…å­˜å­˜å‚¨

### åˆç†æ€§åˆ¤æ–­ï¼š

- âœ… **å­¦ä¹ é¡¹ç›®**: éå¸¸åˆç†ï¼Œé€‚åˆå±•ç¤º
- âš ï¸ **æ ¡æ‹›é¢è¯•**: åŸºæœ¬åˆç†ï¼Œéœ€è¡¥å……äº®ç‚¹
- âŒ **ç”Ÿäº§é¡¹ç›®**: ä¸åˆç†ï¼Œéœ€å¤§å¹…æ”¹è¿›

### é¢è¯•å»ºè®®ï¼š

1. **å¼ºè°ƒå·²å®ç°çš„éƒ¨åˆ†**ï¼ˆç´¢å¼•ã€æ£€ç´¢ã€å¢å¼ºï¼‰
2. **æ‰¿è®¤ä¸è¶³**ï¼ˆæŸ¥è¯¢ä¼˜åŒ–ã€é‡æ’åºï¼‰
3. **è¯´æ˜æ”¹è¿›æ–¹å‘**ï¼ˆæŒä¹…åŒ–ã€æ··åˆæ£€ç´¢ï¼‰
4. **å±•ç¤ºå­¦ä¹ èƒ½åŠ›**ï¼ˆäº†è§£è¡Œä¸šæ ‡å‡†ï¼‰

### æ”¹è¿›ä¼˜å…ˆçº§ï¼š

1. ğŸ”´ **æ¶æ„é‡æ„** - åˆ†ç¦» RAG/FIM
2. ğŸ”´ **æŒä¹…åŒ–å­˜å‚¨** - IndexedDB
3. ğŸŸ¡ **æŸ¥è¯¢ä¼˜åŒ–** - æå–ä¸»é¢˜
4. ğŸŸ¡ **æ··åˆæ£€ç´¢** - Vector + BM25
5. ğŸŸ¢ **ç­”æ¡ˆéªŒè¯** - ç½®ä¿¡åº¦è¯„åˆ†

---

**æœ€ç»ˆè¯„ä»·**: å¯¹äºå­¦ä¹ é¡¹ç›®ï¼Œä½ çš„å®ç°æ˜¯**åˆç†ä¸”ä¼˜ç§€**çš„ã€‚ä½†å¦‚æœè¦ç”¨äºç”Ÿäº§ï¼Œéœ€è¦è¡¥å……æŒä¹…åŒ–å­˜å‚¨ã€æŸ¥è¯¢ä¼˜åŒ–ã€é‡æ’åºç­‰å…³é”®åŠŸèƒ½ã€‚

**å»ºè®®**: ä¿æŒå½“å‰å®ç°ä½œä¸º"åŸºç¡€ç‰ˆ"ï¼Œç„¶åé€æ­¥æ·»åŠ é«˜çº§åŠŸèƒ½ï¼Œå½¢æˆ"è¿›é˜¶ç‰ˆ"ï¼Œè¿™æ ·åœ¨é¢è¯•æ—¶å¯ä»¥å±•ç¤ºä½ çš„è¿­ä»£å’Œä¼˜åŒ–èƒ½åŠ›ã€‚ğŸš€
